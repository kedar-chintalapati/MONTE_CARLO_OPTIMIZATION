# LSM Performance Workbench

This project is a full-stack application and high-performance computing workbench designed to rigorously benchmark various hardware and software optimizations for pricing American options using the Longstaff-Schwartz Monte Carlo (LSM) algorithm.

It features a highly optimized C++/Python backend engine and an interactive React+TypeScript frontend that allows users to design, execute, and analyze performance experiments in real time.

![Workbench Screenshot](analysis/performance_large_workload.png)

## Features

- **Multiple Backends:** Compare performance across eight distinct execution environments:
    - Pure Python (`numpy`)
    - Just-In-Time Compiled Python (`numba`)
    - C++ (Scalar, `std::vector`)
    - C++ (Scalar, Custom Arena Allocator)
    - C++ (SIMD / Vectorized `xsimd`)
    - C++ (Multithreaded, Scalar, Arena)
    - C++ (Multithreaded, SIMD, Arena)
- **Interactive Web UI:** A  frontend built with React and TypeScript provides to act as an experimentation workbench:
    - Control over option and simulation parameters.
    - A parameter sweep interface to run experiments across a range of values.
    - Live polling for the status of long-running, computationally intensive tasks.
    - Intelligent, conditional rendering of results as Bar Charts (for single runs) or Line Charts (for sweeps).
    - "Download as CSV" feature for all generated data.
- **Robust API:** A FastAPI backend handles the C++ engine

## Findings

A finding from this project is a of the practical limits of optimization. While the "Ultimate" backend (combining Multithreading, SIMD, and Arena Allocation) is fast, the **fastest backend on the largest workloads was the Multithreaded Scalar version with Arena Allocation (`cpp_mp`)**.

The `cpp_ultimate` backend, which added the heaviest SIMD instructions on top of the multithreaded workload, was consistently slightly slower than its scalar counterpart on the same number of threads. This could be an example of hardware resource contention:
1.  **(Memory Bandwidth Saturation)** All CPU cores attempting to execute data-hungry AVX instructions simultaneously can saturate the memory bus.
2.  **(Thermal Throttling)** The extreme power draw and heat generated by running a full AVX workload across all cores could force the CPU to reduce its clock speed to stay within a safe thermal envelope, resulting in a net performance loss compared to the cooler-running scalar workload.

This result proves that simply combining all available optimizations does not guarantee the best performance.

## How to Run This Project

To run this application, you will need two separate terminal sessions. Please follow the setup instructions in **[REPRODUCE.md](REPRODUCE.md)** first.

